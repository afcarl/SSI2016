{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Overview of Day 4\n",
    "* Preliminaries\n",
    "* The philosophy of machine learning\n",
    "* Machine learning in Python: why scikit-learn?\n",
    "* Feature extraction\n",
    "* Feature selection\n",
    "* Estimation\n",
    "* Model and parameter selection\n",
    "* Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# We'll load scikit-learn modules as we go,\n",
    "# so we can see what we're using.\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Read in our preprocessed data set from Day 3.\n",
    "# You may need to modify the path to the file\n",
    "# depending on where you put it on your computer.\n",
    "data = pd.read_csv('../data/preprocessed_data.csv')\n",
    "\n",
    "# Since we'll be predicting outcomes, let's restrict\n",
    "# to only common ones. It's hard to predict something\n",
    "# we don't have very many training examples of.\n",
    "data = data.groupby('outcome').filter(lambda x: len(x) >= 500)\n",
    "\n",
    "# Let's also do some recoding to make life easier\n",
    "data = data.dropna(subset=['age'])\n",
    "categoricals = ['sex', 'sterilized']\n",
    "data[categoricals] = data[categoricals].fillna('Unknown')\n",
    "\n",
    "# Important, otherwise we have problems later\n",
    "# when we try to concatenate based on index\n",
    "data = data.reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# The philosophical foundations of machine learning\n",
    "* There aren't really (m)any\n",
    "* Machine learning is an almost ruthlessly pragmatic field\n",
    "* Good prediction is (usually) the main focus of analysis\n",
    "    * Understanding only matters to the extent it helps prediction\n",
    "* This makes iterative model-fitting much more rapid\n",
    "    * Don't need to understand _why_ something works, just need to feel confident that it _does_ work\n",
    "* Places a premium on objective tests of predictive accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Machine learning in Python: why scikit-learn?\n",
    "* There are hundreds of ML packages in Python\n",
    "    * Theano, Tensorflow, orange, Pattern, PyMVPA, etc...\n",
    "* But scikit-learn is dominant\n",
    "    * Elegant, powerful interface\n",
    "    * World-class documentation\n",
    "    * Excellent performance\n",
    "* The exception is deep learning--not supported in scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# The typical predictive modeling pipeline\n",
    "* Feature extraction/engineering\n",
    "* Feature selection\n",
    "* Model/parameter selection\n",
    "* Estimation\n",
    "* Evaluation\n",
    "* Rinse and repeat ad nauseam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Feature extraction\n",
    "* The process of transforming data into more data\n",
    "* We already did lot of this on Day 2\n",
    "* But let's revisit the issue in this new predictive light"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Getting _all_ the features\n",
    "* Well, probably not all... but a _lot_\n",
    "* How much information can we get out of the original dataset?\n",
    "* From an interpretation-oriented standpoint, maybe not much more\n",
    "* From a machine learning standpoint, we've just scratched the surface\n",
    "* Some things we could add: names, colors, any number of interactions...\n",
    "    * The cost of trying out silly things is much lower\n",
    "    * Multicollinearity is not (much of) a concern"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## The bag-of-words model\n",
    "* If you have a lot of data, it's not always worth thinking deeply about your features\n",
    "* E.g., how should we model fur color?\n",
    "    * \"Black/Tricolor\", \"Calico Point\", \"Brown Brindle/Blue Cream\"\n",
    "* Simple approach: treat color descriptions like a [bag-of-words](https://en.wikipedia.org/wiki/Bag-of-words_model)\n",
    "* Extract all word tokens (possibly even N-grams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# First 20 unique colors in the dataset\n",
    "data['color'].unique()[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# The CountVectorizer is an estimator that takes a series\n",
    "# of documents (or strings) as input, and returns a count\n",
    "# of every word token found in every document. There's also\n",
    "# a TfidfVectorizer in cases where we want normalized frequency.\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Initialize the CountVectorizer with default parameters.\n",
    "# Some common arguments we might want to experiment with\n",
    "# include min_df and max_df (which exclude words that are\n",
    "# too frequent or infrequent), stop_words (which allows\n",
    "# us to pass in a list of words to ignore), and ngram_range,\n",
    "# which enables us to extract multi-word features.\n",
    "vec = CountVectorizer()\n",
    "\n",
    "# Extract all possible word features from the color list.\n",
    "# Note that this returns a sparse matrix rather than a\n",
    "# numpy array or a pandas DataFrame. A sparse matrix is\n",
    "# a way of representing potentially very large 2-d arrays\n",
    "# very efficiently, because we don't need to allocate\n",
    "# memory for every cell in the array, only those that\n",
    "# have a non-zero value.\n",
    "fur_features = vec.fit_transform(data['color'])\n",
    "print(\"fur_features is an object of type:\", type(fur_features))\n",
    "\n",
    "# After fitting, the names of the features (i.e., the\n",
    "# columns of the sparse matrix returned by fit_transform())\n",
    "# are stored in the estimator itself.\n",
    "feature_names = vec.get_feature_names()\n",
    "\n",
    "# Store in a pandas DF for easier manipulation later.\n",
    "# Note that we convert the sparse array back to a dense\n",
    "# one before loading into pandas. If our dataset were\n",
    "# much bigger, we'd probably want to avoid this step\n",
    "# and just keep working with the sparse matrix.\n",
    "fur_features = pd.DataFrame(fur_features.todense(), columns=feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Let's take a look...\n",
    "fur_features.head(10)\n",
    "# fur_features.sum(axis=0).sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Generalizing the pattern\n",
    "* We might want to do the same thing for other text features\n",
    "* Let's write a little method that does count vectorizing for any dataset column\n",
    "* We'll run it on our \"breed\" column, then concatenate the two into one dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Adding interaction terms\n",
    "* We could dummy-code all our categorical variables and then take pairwise products\n",
    "* But if we don't need interpretabilty, there's a simpler hack\n",
    "    * Concatenate all variables for which we want interactions\n",
    "    * Dummy-code the result\n",
    "* Let's cross sex, sterilization, and breed (that's a lot of features!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Simply concatenate the columns we want--making sure to convert any numeric\n",
    "# columns to string, otherwise the concatenation will fail.\n",
    "data['ssb'] = data['sex'].astype(str) + '_' + data['sterilized'].astype(str) + '_' + data['breed']\n",
    "\n",
    "# How many unique levels?\n",
    "num_levels = data['ssb'].nunique()\n",
    "print(\"Total number of unique values: {}\".format(num_levels))\n",
    "\n",
    "# Now we can dummy-code the result\n",
    "# pd.get_dummies(data['ssb']).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### What else?\n",
    "* Very easy to quickly build up thousands of derivative features in this way\n",
    "* Doesn't mean we shouldn't think deeply about good features\n",
    "    * Often, biggest jumps in performance are achieved by adding entirely new features\n",
    "* Point is try to eke out every bit of signal from what we have"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Feature selection/reduction\n",
    "* Not all features are created equal\n",
    "* Just because we created 10,000 features doesn't mean we need to include them all\n",
    "* Two general approaches:\n",
    "    * Dimensionality reduction (extract latent signal from observed features)\n",
    "    * Feature selection (filter out features based on some criterion)\n",
    "* Supported by the feature_selection, clustering, and decomposition modules in sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Decomposition\n",
    "* Techniques for decomposing/factoring matrices\n",
    "    * [sklearn.decomposition](http://scikit-learn.org/stable/modules/classes.html#module-sklearn.decomposition)\n",
    "    * PCA, ICA, dictionary learning, many others\n",
    "* Reduce dimensionality by extracting signal common to multiple features\n",
    "* Can we reduce our 3,000+ strong set of features to a smaller number?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# First we need to recode our string column as a set of dummies\n",
    "interaction_dummies = pd.get_dummies(data['ssb'])\n",
    "\n",
    "# Let's concatenate this with the color features\n",
    "# axis=1 indicates that we want to concatenate along\n",
    "# the column axis (axis=0 would append each dataframe\n",
    "# below the last.\n",
    "lotsa_features = pd.concat([fur_features, interaction_dummies], axis=1)\n",
    "\n",
    "# Like most other things in sklearn, decomposition classes\n",
    "# implement the estimator interface. So they have fit() and\n",
    "# predict() methods. Transformers also have a transform()\n",
    "# method. First, we initialize the RandomizedPCA transformer.\n",
    "# RandomizedPCA is a speedier approximation of the standard\n",
    "# principal component analysis (PCA) factorization. We need to\n",
    "# specify the number of components we want at initialization.\n",
    "# We'll take the first 100.\n",
    "from sklearn.decomposition import RandomizedPCA\n",
    "pca = RandomizedPCA(100)\n",
    "\n",
    "# Now we can fit and transform in one step\n",
    "pca_features = pca.fit_transform(lotsa_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# How much of the variance do these components explain?\n",
    "exp_variance = pca.explained_variance_ratio_.sum()\n",
    "msg = \"All components collectively explain {:.0%} of the variance.\"\n",
    "print(msg.format(exp_variance))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Let's take a look at the scree plot\n",
    "plt.plot(pca.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# We can look at the loadings if we want to try to understand what's going on\n",
    "components = pca.components_\n",
    "loadings = pd.DataFrame(components, columns=lotsa_features.columns)\n",
    "loadings.iloc[0].sort_values(ascending=False)\n",
    "\n",
    "# As an exercise, you can come up with a better way to visualize what's\n",
    "# going on. For example, you could pick out some of the most common\n",
    "# features in the original space (by summing each of the columns over\n",
    "# the rows), and then plot a heatmap of loadings of the first 10\n",
    "# PCA components against the 10 most commonly occurring features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Clustering\n",
    "* The goal of clustering is to identify homogeneous clusters of cases in the data\n",
    "* Ideally, these clusters align well with clear natural boundaries\n",
    "    * E.g., clustering the animal data produces a cat cluster, dog cluster, etc.\n",
    "* With real-world data, they rarely do\n",
    "* Clustering is a convenient way to describe data, **not** a window onto underlying reality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Illustration of clustering methods (from the [scikit-learn docs](http://scikit-learn.org/stable/modules/clustering.html))\n",
    "<img src=\"http://scikit-learn.org/stable/_images/plot_cluster_comparison_0011.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### What features should we cluster on?\n",
    "* There is no \"true\" clustering; everything depends on the features we pick\n",
    "* Clustering can get very slow for large n_samples and/or n_features\n",
    "* Often (as in this case) doesn't make sense in presence of mostly categoricals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Selecting features\n",
    "* The preceding approaches all involve selecting or creating new features\n",
    "* But we could also just keep some and throw out others\n",
    "* Many things we can select for:\n",
    "    - Keep high-variance features\n",
    "    - Keep best-scoring features (i.e., strongest correlation with outcome)\n",
    "    - Fit a preliminary estimator like lasso that includes feature selection\n",
    "    - etc..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# We'll use \"KBest\" feature selection, which simply retains the\n",
    "# top K features, as ranked by their correlation with the\n",
    "# outcome of interest. There are plenty of other options\n",
    "# inside the feature_selection module. Note that because\n",
    "# there are multiple classes in our outcome variable, we'll\n",
    "# need to first extract a performance metric we can rank.\n",
    "# For that, we can use the chi2 scoring function, which gives\n",
    "# us the chi2 score for the outcome against each feature.\n",
    "from sklearn.feature_selection import chi2, SelectKBest\n",
    "\n",
    "# Let's pick 100 features, to match the PCA above.\n",
    "# Notice that sklearn accepts a scoring function as the\n",
    "# first argument, so we don't even have to compute the chi2\n",
    "# scores ourselves--we just pass the ranking method directly\n",
    "# to the SelectKBest instance!\n",
    "slctr = SelectKBest(chi2, k=100)\n",
    "\n",
    "# We do, however, need to convert the outcome string to\n",
    "# integer class labels. Fortunately, sklearn has a utility\n",
    "# for that. The LabelEncoder is also an estimator, so\n",
    "# we need to initialize it before we fit_transform.\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "encoder = LabelEncoder()\n",
    "y = encoder.fit_transform(data['outcome'])\n",
    "\n",
    "# We'll apply to the same set of color and sex/sterilized/breed features\n",
    "selected_features = slctr.fit_transform(lotsa_features, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Let's see what features were kept..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# After transformation, the names of the selected features\n",
    "# will be stored as a boolean array in the estimator.\n",
    "# We can index the pandas DataFrame column with this\n",
    "# array to see which features were kept.\n",
    "selected_inds = slctr.get_support()\n",
    "lotsa_features.columns[selected_inds]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Estimation\n",
    "* With features in hand, we can now fit some models!\n",
    "* scikit-learn has a bewildering array of models\n",
    "* We'll talk about model selection shortly\n",
    "* For now, let's stick with logistic regression\n",
    "    * We'll try to predict animal outcomes again\n",
    "    * A twist: we're now doing multi-class classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Initialize our logistic regression estimator\n",
    "est = LogisticRegression()\n",
    "\n",
    "# Let's start with a really simple model: predicting\n",
    "# outcome from just the animal's age (plus an intercept,\n",
    "# which is added automatically).\n",
    "X = data[['age']]\n",
    "\n",
    "# We already did this above, but let's do it again,\n",
    "# just so it's clear where y is coming from.\n",
    "y = LabelEncoder().fit_transform(data['outcome'])\n",
    "\n",
    "# Fitting the model is as simple as passing\n",
    "# the X and y arrays to fit().\n",
    "est.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### How did we do?\n",
    "* Our model is fitted! Let's see how accurately we classified outcomes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Predict y from the trained model. Note that\n",
    "# scikit-learn will not do this for you automatically.\n",
    "# So we call predict(), passing in only the X this\n",
    "# time (since we've already trained on y).\n",
    "y_predicted = est.predict(X)\n",
    "\n",
    "# Now we have a variety of evaluation metrics.\n",
    "# We'll talk about those below. The simplest one is\n",
    "# to just look at the number of cases we classified\n",
    "# correctly.\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Most scoring functions in metrics take the true\n",
    "# labels and the predicted labels, in that order.\n",
    "scores = accuracy_score(y, y_predicted)\n",
    "print(\"Overall classification accuracy: {:.0%}\".format(scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Is this good?\n",
    "* Seems good, no?\n",
    "* There are 4 classes, so chance should be 25%, right?\n",
    "* Or should it..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "counts = data['outcome'].value_counts()\n",
    "counts/counts.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Evaluation\n",
    "* Evaluating model performance is rarely straightforward\n",
    "* There are many criteria we might value\n",
    "* Simple answers can be misleading\n",
    "* Let's take a look at _how_ we classified different outcomes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Confusion matrix\n",
    "* How does the classifier go wrong?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def plot_confusion_matrix(y, y_predicted):\n",
    "    ''' take true and predicted scores and plot confusion matrix '''\n",
    "    # Get the confusion matrix\n",
    "    cm = confusion_matrix(y, y_predicted)\n",
    "\n",
    "    # Normalize the confusion matrix by dividing each row by its sum\n",
    "    ncm = cm / cm.sum(axis=1)[:, None]\n",
    "\n",
    "    # Put into DataFrame and get all labels from the encoder\n",
    "    class_labels = encoder.classes_\n",
    "    ncm = pd.DataFrame(ncm, index=class_labels, columns=class_labels)\n",
    "\n",
    "    # Rows are true classes, columns are assigned classes\n",
    "    sns.heatmap(data=ncm, fmt='.2f', annot=True)\n",
    "    \n",
    "plot_confusion_matrix(y, y_predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Ruh-roh...\n",
    "* That 38% accuracy rate is a little misleading\n",
    "* The classifier is performing this well by assigning the same class everywhere\n",
    "* We need to fix this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# The classification report shows us performance for\n",
    "# the most common metrics, by class\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y, y_predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Iterating\n",
    "* Let's iteratively try to improve the model performance by:\n",
    "    * Adding features (we have plenty!)\n",
    "    * Making sure the estimator respects class weights\n",
    "    * Trying different estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# For models with categoricals, we can call on\n",
    "# patsy to dummy-code our variables, like we did\n",
    "# when working with statsmodels\n",
    "from patsy import dmatrices\n",
    "\n",
    "# Some estimators we can try (there are many more!)\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "\n",
    "est = LogisticRegression()\n",
    "\n",
    "# Set up the features--let's go big this time\n",
    "X = data[['age', 'sex', 'sterilized']]\n",
    "\n",
    "# We already set up y, so we're just passing in 1 here\n",
    "# as a dummy. Note that we store it in a variable named\n",
    "# _ on the return, which is a convention to indicate\n",
    "# somethign we want to throw away. It's only the X's\n",
    "# we care about here.\n",
    "_, X = dmatrices('1 ~ age + C(sex) + C(sterilized)', data=X)\n",
    "\n",
    "# Add in the features we extracted/selected\n",
    "# X = np.c_[X.data, selected_features]\n",
    "X = np.c_[X.data, lotsa_features]\n",
    "# X = np.c_[X.data, selected_features]\n",
    "\n",
    "est.fit(X, y)\n",
    "\n",
    "y_predicted = est.predict(X)\n",
    "\n",
    "scores = accuracy_score(y, y_predicted)\n",
    "print(\"Overall classification accuracy: {:.0%}\".format(scores))\n",
    "\n",
    "plot_confusion_matrix(y, y_predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Cross-validation\n",
    "* Hopefully performance now looks reasonable\n",
    "* But there's still a potential problem: overfitting\n",
    "* We're training and evaluating on the same dataset--this is a big no-no!\n",
    "* scikit-learn provides easy ways to evaluate models out-of-sample\n",
    "    * This is known as cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Import KFold cross-validation\n",
    "from sklearn.cross_validation import KFold\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# Placeholder for scores from each fold\n",
    "scores = []\n",
    "\n",
    "# Create k folds (in our case 5). Loop over the folds,\n",
    "# and for each one, split the dataset into training and test.\n",
    "# In each fold, we train the data on the training values,\n",
    "# and then evaluate its performance on the test. Finally,\n",
    "# we can take the average of the out-of-sample scores as\n",
    "# our estimate of model performance.\n",
    "for train, test in KFold(n=len(X), n_folds=5, shuffle=True):\n",
    "    \n",
    "    est.fit(X[train], y[train])\n",
    "    pred_y = est.predict(X[test])\n",
    "    fold_score = f1_score(y[test], pred_y, average='weighted')\n",
    "    scores.append(fold_score)\n",
    "\n",
    "print(np.array(scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Model selection\n",
    "* We've experimented a lot with estimators, decomposition, evaluation, etc.\n",
    "* This is only the tip of the iceberg...\n",
    "* scikit-learn has hundreds of estimators!\n",
    "* Two problems:\n",
    "    1. How are we supposed to choose?\n",
    "    2. How do we do this in a principled way?\n",
    "* Requirement for both is an automated, principled way to execute a pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fully automated pipelines\n",
    "* We've done feature extraction, reduction, and selection; estimation; evaluation...\n",
    "* But we need to automate this\n",
    "    * Both for efficiency, and to prevent overfitting\n",
    "* sklearn.pipeline provides functionality for creating [fully automated Pipelines](http://scikit-learn.org/stable/modules/pipeline.html)\n",
    "* We'll build a toy example with 2 steps, but we could chain our entire workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Import the Pipeline class\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Initialize a list to store all the steps in our pipeline\n",
    "steps = []\n",
    "\n",
    "# Add feature selection\n",
    "selector = SelectKBest(k=100)\n",
    "steps.append(('select', selector))\n",
    "\n",
    "# Add estimation\n",
    "estimator = LogisticRegression()\n",
    "steps.append(('estimate', estimator))\n",
    "\n",
    "# Initialize the pipeline\n",
    "pipeline = Pipeline(steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Fit the pipeline\n",
    "_y_pred = pipeline.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "## The fit-predict interface\n",
    "* scikit-learn is built around the estimator interface\n",
    "* \"An estimator is an object that fits a model based on some training data and is capable of inferring some properties on new data\"\n",
    "* Every estimator must implement fit() and predict() methods\n",
    "* Makes it easy to extend scikit-learn with our own estimators"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "### Building our own estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "\n",
    "class MercurialClassifier(BaseEstimator, ClassifierMixin):\n",
    "    \"\"\"Picks a random class and assigns that label to all cases.\"\"\"\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        ''' Selects a random class from the available options '''\n",
    "        classes = np.unique(y)\n",
    "        self.selected_ = np.random.choice(classes)\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        ''' Applies the selected class to everything '''\n",
    "        return np.repeat(self.selected_, len(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# The End\n",
    "* I hope you enjoyed the course and/or learned something useful!\n",
    "* The links throughout the notebooks contain plenty of further resources\n",
    "* Consider registering for [SciPy 2016](scipy2016.scipy.org) (here in July)--they have great tutorials\n",
    "* Feedback/suggestions for improvement is welcome\n",
    "* Please fill out a course evaluation before you leave"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
